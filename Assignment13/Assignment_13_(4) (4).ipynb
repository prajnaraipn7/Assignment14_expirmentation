{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment_13 (4).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sw4nNhM8mN2z",
        "outputId": "f8628996-b17f-4af2-93e4-8e359bed4e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout,SpatialDropout2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D,ZeroPadding2D,AveragePooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input,add\n",
        "from keras.models import Model\n",
        "from keras.layers import concatenate \n",
        "from keras.layers import GlobalAveragePooling2D"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VeLRe4cBmbu_",
        "outputId": "9531d5e2-b364-4ab1-bd16-29eff14b72f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#loading dataset\n",
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9Men1oDmesN",
        "colab": {}
      },
      "source": [
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "# convert class labels to binary class labels\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q5EigjQNmhWU",
        "colab": {}
      },
      "source": [
        "def get_cutout_eraser_and_random_crop(p=0.5,s_l=0.05,s_h=0.3,r_1=0.3,r_2=1/0.3,max_erasers_per_image=1,pixel_level=True,random_crop_size=(32,32),padding_pixels=4):\n",
        "  \n",
        "  assert max_erasers_per_image>=1 \n",
        "  def eraser(input_img):\n",
        "        v_l = np.min(input_img)\n",
        "        v_h = np.max(input_img)\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "        mx = np.random.randint(1,max_erasers_per_image+1)\n",
        "        for i in range(mx):\n",
        "          while True:\n",
        "              s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "              r = np.random.uniform(r_1, r_2)\n",
        "              w = int(np.sqrt(s / r))\n",
        "              h = int(np.sqrt(s * r))\n",
        "              left = np.random.randint(0, img_w)\n",
        "              top = np.random.randint(0, img_h)\n",
        "\n",
        "              if left + w <= img_w and top + h <= img_h:\n",
        "                  break\n",
        "\n",
        "          if pixel_level:\n",
        "              c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "          else:\n",
        "              c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "          input_img[top:top + h, left:left + w, :] = c\n",
        "        return input_img\n",
        "\n",
        "    \n",
        "  def random_crop(input_image):\n",
        "    assert input_image.shape[2]==3\n",
        "\n",
        "    #pad for 4 pixels\n",
        "    img = cv2.copyMakeBorder(input_image,padding_pixels,padding_pixels,padding_pixels,padding_pixels,cv2.BORDER_REPLICATE)\n",
        "    height , width =img.shape[0],img.shape[1]\n",
        "    dy,dx = random_crop_size\n",
        "    x = np.random.randint(0,width - dx + 1)\n",
        "    y = np.random.randint(0,height - dy + 1)\n",
        "    return img[y:(y+dy),x:(x+dx),:]\n",
        "\n",
        "  def preprocess_image(input_image):\n",
        "    return eraser(random_crop(input_image))\n",
        "  \n",
        "  return preprocess_image\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2tOuprdCpqSB",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=0.5,preprocessing_function=get_cutout_eraser_and_random_crop())\n",
        "test_datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True)\n",
        "#test_datagen.fit(train_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AMi1CeDsqUyv",
        "colab": {}
      },
      "source": [
        "datagen.mean = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "datagen.std = np.array([0.2023, 0.1994, 0.2010], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Za7Xax0zyZc2"
      },
      "source": [
        "#Resnet Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B41YNxNtCUwa",
        "colab": {}
      },
      "source": [
        "def ResNetBlock(input_layer, channels,stride=1):\n",
        "  \n",
        "  bn_1 = BatchNormalization(momentum=0.9,epsilon=1e-5)(input_layer)\n",
        "  activation_layer_b1 = Activation('relu')(bn_1)\n",
        "  block_layer_1 = Convolution2D(channels, (3,3), padding='same',strides=stride)(activation_layer_b1)\n",
        "  \n",
        "  bn_2 = BatchNormalization(momentum=0.9,epsilon=1e-5)(block_layer_1)\n",
        "  activation_layer_b2 = Activation('relu')(bn_2) \n",
        "  block_layer_2 = Convolution2D(channels, (3,3), padding='same')(activation_layer_b2)\n",
        "   \n",
        "  \n",
        "  return block_layer_2\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7zl45v4UBTff",
        "outputId": "7327bd41-66ef-4d4f-bd25-f2b26d0b6470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "from keras.layers import Input, add, GlobalAveragePooling2D, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "inputs =Input(shape=(32, 32, 3))\n",
        "\n",
        "x1 = Convolution2D(32, (3, 3),padding='same')(inputs)   #32x32 \n",
        "activation_x1 = Activation('relu')(x1)\n",
        "bn1 = BatchNormalization(momentum=0.9,epsilon=1e-5)(activation_x1)\n",
        "\n",
        "x2 = Convolution2D(32, (3, 3),padding='same')(bn1)   #32x32 \n",
        "activation_x2 = Activation('relu')(x2)\n",
        "bn2 = BatchNormalization()(activation_x2)\n",
        "\n",
        "# x3 = Convolution2D(64, (3, 3),padding='same')(bn2)   #32x32 \n",
        "# activation_x3 = Activation('relu')(x3)\n",
        "# bn3 = BatchNormalization()(activation_x3)\n",
        "\n",
        "\n",
        "##block 1\n",
        "\n",
        "blk1 = ResNetBlock(bn2,32)  ##32x32\n",
        "z1 = add([blk1,bn2])\n",
        "\n",
        "blk1_c = ResNetBlock(z1,32)\n",
        "z1_c = add([blk1_c,z1])\n",
        "\n",
        "drp1 = SpatialDropout2D(0.05)(z1_c)\n",
        "\n",
        "##block 2\n",
        "\n",
        "blk2 = ResNetBlock(drp1,64,stride=2)\n",
        "one_blk = Convolution2D(64, (1, 1), padding='same',strides=2)(drp1)\n",
        "z2 = add([blk2,one_blk])\n",
        "\n",
        "blk2_c = ResNetBlock(z2,64)\n",
        "z2_c = add([blk2_c,z2])\n",
        "\n",
        "drp2 = SpatialDropout2D(0.05)(z2_c)\n",
        "\n",
        "##block3\n",
        "\n",
        "blk3 = ResNetBlock(drp2,128)\n",
        "one_blk_1 = Convolution2D(128, (1, 1), padding='same')(drp2)\n",
        "z3 = add([blk3,one_blk_1])\n",
        "\n",
        "blk3_c = ResNetBlock(z3,128)\n",
        "z3_c = add([blk3_c,z3])\n",
        "\n",
        "# drp3 = SpatialDropout2D(0.05)(z3_c)\n",
        "##block4\n",
        "\n",
        "# blk4 = ResNetBlock(drp3,256,stride=2)\n",
        "# one_blk_2 = Convolution2D(256, (1, 1), padding='same',strides=2)(drp3)\n",
        "# z4 = add([blk4,one_blk_2])\n",
        "\n",
        "# blk4_c = ResNetBlock(z4,256)\n",
        "# z4_c = add([blk4_c,z4])\n",
        "\n",
        "\n",
        "avg_pool_layer = GlobalAveragePooling2D()(z3_c)\n",
        "\n",
        "#flatten_layer = Flatten()(avg_pool_layer)\n",
        "\n",
        "fc_layer = Dense(10, activation='softmax')(avg_pool_layer)\n",
        "\n",
        "\n",
        "model = Model(inputs=inputs, outputs= fc_layer)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0805 12:00:26.328115 140136275920768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0805 12:00:26.373179 140136275920768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0805 12:00:26.380679 140136275920768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0805 12:00:26.422042 140136275920768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0805 12:00:26.423027 140136275920768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0805 12:00:29.340350 140136275920768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0805 12:00:29.915984 140136275920768 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sV-nVdlMDwva",
        "outputId": "b1933fce-918e-4d71-c732-23f6e4b548f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   9248        batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9248        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   9248        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 32)   9248        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 32)   0           conv2d_6[0][0]                   \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_1 (SpatialDro (None, 32, 32, 32)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   18496       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 64)   2112        spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 64)   0           conv2d_8[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 64)   36928       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 64)   0           conv2d_11[0][0]                  \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_2 (SpatialDro (None, 16, 16, 64)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         spatial_dropout2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 128)  73856       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 128)  147584      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 128)  8320        spatial_dropout2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 128)  0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 128)  0           conv2d_16[0][0]                  \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 128)          0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           1290        global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 708,202\n",
            "Trainable params: 706,474\n",
            "Non-trainable params: 1,728\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZl_uafGb3r9",
        "colab": {}
      },
      "source": [
        "#from one_cycle_lr import LRFinder\n",
        "from one_cycle_lr import LRFinder\n",
        "num_samples= train_features.shape[0]\n",
        "batch_size =512\n",
        "num_epoch=30\n",
        "max_lr= 0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDMPrA1Gj01s"
      },
      "source": [
        "#Best LR would be 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PjzOgXaWj_uE",
        "outputId": "5c62af9d-9c89-4350-f5bf-fda589f9248b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "opt = optimizers.SGD(decay=5e-4)\n",
        "model.compile(optimizer=opt , loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0805 12:01:14.854370 140136275920768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XaDmx-zQlExS",
        "colab": {}
      },
      "source": [
        "from one_cycle_lr import OneCycleLR\n",
        "\n",
        "lr_manager = OneCycleLR(num_samples, num_epoch, batch_size, max_lr,\n",
        "                        end_percentage=0.1, scale_percentage=None,\n",
        "                        maximum_momentum=0.95, minimum_momentum=0.85)\n",
        "                        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sDeQk2bZqTGp",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "upsNiPO4JWjb",
        "outputId": "e0f7fe9f-3dcc-4470-ead6-8b78a0c0fc6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filepath = \"Resnet-13.hdf5\"\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 512),\n",
        "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 30, \n",
        "                                 validation_data = (test_features, test_labels), verbose=1,callbacks=[checkpoint,lr_manager])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., verbose=1, callbacks=[<keras.ca..., steps_per_epoch=97, epochs=30)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "W0805 12:01:33.139751 140136275920768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "97/97 [==============================] - 31s 318ms/step - loss: 1.8885 - acc: 0.3002 - val_loss: 2.0573 - val_acc: 0.3485\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.34850, saving model to Resnet-13.hdf5\n",
            " - lr: 0.01660 - momentum: 0.94 \n",
            "Epoch 2/30\n",
            "97/97 [==============================] - 25s 259ms/step - loss: 1.5333 - acc: 0.4400 - val_loss: 2.2814 - val_acc: 0.3388\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.34850\n",
            " - lr: 0.02327 - momentum: 0.94 \n",
            "Epoch 3/30\n",
            "97/97 [==============================] - 25s 253ms/step - loss: 1.3311 - acc: 0.5151 - val_loss: 1.4571 - val_acc: 0.5129\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.34850 to 0.51290, saving model to Resnet-13.hdf5\n",
            " - lr: 0.02994 - momentum: 0.93 \n",
            "Epoch 4/30\n",
            "97/97 [==============================] - 25s 256ms/step - loss: 1.2007 - acc: 0.5664 - val_loss: 1.2891 - val_acc: 0.5613\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.51290 to 0.56130, saving model to Resnet-13.hdf5\n",
            " - lr: 0.03661 - momentum: 0.92 \n",
            "Epoch 5/30\n",
            "97/97 [==============================] - 25s 257ms/step - loss: 1.0916 - acc: 0.6112 - val_loss: 1.6319 - val_acc: 0.5107\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.56130\n",
            " - lr: 0.04328 - momentum: 0.91 \n",
            "Epoch 6/30\n",
            "97/97 [==============================] - 25s 259ms/step - loss: 1.0208 - acc: 0.6344 - val_loss: 1.2024 - val_acc: 0.5972\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.56130 to 0.59720, saving model to Resnet-13.hdf5\n",
            " - lr: 0.04995 - momentum: 0.91 \n",
            "Epoch 7/30\n",
            "97/97 [==============================] - 25s 261ms/step - loss: 0.9630 - acc: 0.6570 - val_loss: 1.0169 - val_acc: 0.6535\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.59720 to 0.65350, saving model to Resnet-13.hdf5\n",
            " - lr: 0.05662 - momentum: 0.90 \n",
            "Epoch 8/30\n",
            "97/97 [==============================] - 25s 262ms/step - loss: 0.8958 - acc: 0.6805 - val_loss: 0.9380 - val_acc: 0.6766\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.65350 to 0.67660, saving model to Resnet-13.hdf5\n",
            " - lr: 0.06328 - momentum: 0.89 \n",
            "Epoch 9/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.8452 - acc: 0.6986 - val_loss: 0.8690 - val_acc: 0.6978\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.67660 to 0.69780, saving model to Resnet-13.hdf5\n",
            " - lr: 0.06995 - momentum: 0.88 \n",
            "Epoch 10/30\n",
            "97/97 [==============================] - 26s 264ms/step - loss: 0.8020 - acc: 0.7178 - val_loss: 1.0965 - val_acc: 0.6773\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.69780\n",
            " - lr: 0.07662 - momentum: 0.88 \n",
            "Epoch 11/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.7767 - acc: 0.7247 - val_loss: 0.8978 - val_acc: 0.6987\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.69780 to 0.69870, saving model to Resnet-13.hdf5\n",
            " - lr: 0.08329 - momentum: 0.87 \n",
            "Epoch 12/30\n",
            "97/97 [==============================] - 26s 264ms/step - loss: 0.7316 - acc: 0.7425 - val_loss: 0.8855 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.69870 to 0.71930, saving model to Resnet-13.hdf5\n",
            " - lr: 0.08996 - momentum: 0.86 \n",
            "Epoch 13/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.6981 - acc: 0.7554 - val_loss: 0.6462 - val_acc: 0.7793\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.71930 to 0.77930, saving model to Resnet-13.hdf5\n",
            " - lr: 0.09663 - momentum: 0.85 \n",
            "Epoch 14/30\n",
            "97/97 [==============================] - 26s 264ms/step - loss: 0.6649 - acc: 0.7678 - val_loss: 0.6664 - val_acc: 0.7798\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.77930 to 0.77980, saving model to Resnet-13.hdf5\n",
            " - lr: 0.09670 - momentum: 0.85 \n",
            "Epoch 15/30\n",
            "97/97 [==============================] - 26s 264ms/step - loss: 0.6325 - acc: 0.7803 - val_loss: 0.7899 - val_acc: 0.7479\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.77980\n",
            " - lr: 0.09003 - momentum: 0.86 \n",
            "Epoch 16/30\n",
            "97/97 [==============================] - 26s 264ms/step - loss: 0.6087 - acc: 0.7885 - val_loss: 0.6723 - val_acc: 0.7703\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.77980\n",
            " - lr: 0.08336 - momentum: 0.87 \n",
            "Epoch 17/30\n",
            "97/97 [==============================] - 26s 264ms/step - loss: 0.5858 - acc: 0.7955 - val_loss: 0.6435 - val_acc: 0.7933\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.77980 to 0.79330, saving model to Resnet-13.hdf5\n",
            " - lr: 0.07669 - momentum: 0.88 \n",
            "Epoch 18/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.5685 - acc: 0.8019 - val_loss: 0.6537 - val_acc: 0.7964\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.79330 to 0.79640, saving model to Resnet-13.hdf5\n",
            " - lr: 0.07002 - momentum: 0.88 \n",
            "Epoch 19/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.5384 - acc: 0.8119 - val_loss: 0.6825 - val_acc: 0.7835\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.79640\n",
            " - lr: 0.06335 - momentum: 0.89 \n",
            "Epoch 20/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.5249 - acc: 0.8183 - val_loss: 0.6046 - val_acc: 0.8044\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.79640 to 0.80440, saving model to Resnet-13.hdf5\n",
            " - lr: 0.05668 - momentum: 0.90 \n",
            "Epoch 21/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.5130 - acc: 0.8217 - val_loss: 0.5509 - val_acc: 0.8178\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.80440 to 0.81780, saving model to Resnet-13.hdf5\n",
            " - lr: 0.05002 - momentum: 0.91 \n",
            "Epoch 22/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.4825 - acc: 0.8330 - val_loss: 0.4966 - val_acc: 0.8322\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.81780 to 0.83220, saving model to Resnet-13.hdf5\n",
            " - lr: 0.04335 - momentum: 0.91 \n",
            "Epoch 23/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.4775 - acc: 0.8339 - val_loss: 0.5582 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.83220\n",
            " - lr: 0.03668 - momentum: 0.92 \n",
            "Epoch 24/30\n",
            "97/97 [==============================] - 26s 263ms/step - loss: 0.4671 - acc: 0.8358 - val_loss: 0.4830 - val_acc: 0.8414\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.83220 to 0.84140, saving model to Resnet-13.hdf5\n",
            " - lr: 0.03001 - momentum: 0.93 \n",
            "Epoch 25/30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ADKRdQnkKQ_z",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}