{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment_13 (4).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sw4nNhM8mN2z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89a1e71d-2ba8-4f3e-f8d2-30f45399af40"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout,SpatialDropout2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D,ZeroPadding2D,AveragePooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input,add\n",
        "from keras.models import Model\n",
        "from keras.layers import concatenate \n",
        "from keras.layers import GlobalAveragePooling2D"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VeLRe4cBmbu_",
        "outputId": "68963d13-8428-4999-c853-7ebafc97745d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#loading dataset\n",
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 9s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9Men1oDmesN",
        "colab": {}
      },
      "source": [
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "# convert class labels to binary class labels\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q5EigjQNmhWU",
        "colab": {}
      },
      "source": [
        "def get_cutout_eraser_and_random_crop(p=0.5,s_l=0.05,s_h=0.3,r_1=0.3,r_2=1/0.3,max_erasers_per_image=1,pixel_level=True,random_crop_size=(32,32),padding_pixels=4):\n",
        "  \n",
        "  assert max_erasers_per_image>=1 \n",
        "  def eraser(input_img):\n",
        "        v_l = np.min(input_img)\n",
        "        v_h = np.max(input_img)\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "        mx = np.random.randint(1,max_erasers_per_image+1)\n",
        "        for i in range(mx):\n",
        "          while True:\n",
        "              s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "              r = np.random.uniform(r_1, r_2)\n",
        "              w = int(np.sqrt(s / r))\n",
        "              h = int(np.sqrt(s * r))\n",
        "              left = np.random.randint(0, img_w)\n",
        "              top = np.random.randint(0, img_h)\n",
        "\n",
        "              if left + w <= img_w and top + h <= img_h:\n",
        "                  break\n",
        "\n",
        "          if pixel_level:\n",
        "              c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "          else:\n",
        "              c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "          input_img[top:top + h, left:left + w, :] = c\n",
        "        return input_img\n",
        "\n",
        "    \n",
        "  def random_crop(input_image):\n",
        "    assert input_image.shape[2]==3\n",
        "\n",
        "    #pad for 4 pixels\n",
        "    img = cv2.copyMakeBorder(input_image,padding_pixels,padding_pixels,padding_pixels,padding_pixels,cv2.BORDER_REPLICATE)\n",
        "    height , width =img.shape[0],img.shape[1]\n",
        "    dy,dx = random_crop_size\n",
        "    x = np.random.randint(0,width - dx + 1)\n",
        "    y = np.random.randint(0,height - dy + 1)\n",
        "    return img[y:(y+dy),x:(x+dx),:]\n",
        "\n",
        "  def preprocess_image(input_image):\n",
        "    return eraser(random_crop(input_image))\n",
        "  \n",
        "  return preprocess_image\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2tOuprdCpqSB",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=0.5,preprocessing_function=get_cutout_eraser_and_random_crop())\n",
        "test_datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True)\n",
        "#test_datagen.fit(train_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AMi1CeDsqUyv",
        "colab": {}
      },
      "source": [
        "datagen.mean = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "datagen.std = np.array([0.2023, 0.1994, 0.2010], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Za7Xax0zyZc2"
      },
      "source": [
        "#Resnet Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B41YNxNtCUwa",
        "colab": {}
      },
      "source": [
        "def ResNetBlock(input_layer, channels,stride=1):\n",
        "  \n",
        "  bn_1 = BatchNormalization()(input_layer)\n",
        "  activation_layer_b1 = Activation('relu')(bn_1)\n",
        "  block_layer_1 = Convolution2D(channels, (3,3), padding='same',strides=stride)(activation_layer_b1)\n",
        "  \n",
        "  bn_2 = BatchNormalization()(block_layer_1)\n",
        "  activation_layer_b2 = Activation('relu')(bn_2) \n",
        "  block_layer_2 = Convolution2D(channels, (3,3), padding='same')(activation_layer_b2)\n",
        "   \n",
        "  \n",
        "  return block_layer_2\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7zl45v4UBTff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "6c5599ef-472b-4389-9234-0f388aeb9bcf"
      },
      "source": [
        "from keras.layers import Input, add, GlobalAveragePooling2D, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "inputs =Input(shape=(32, 32, 3))\n",
        "\n",
        "x1 = Convolution2D(32, (3, 3),padding='same')(inputs)   #32x32 \n",
        "activation_x1 = Activation('relu')(x1)\n",
        "bn1 = BatchNormalization()(activation_x1)\n",
        "\n",
        "# x2 = Convolution2D(64, (3, 3),padding='same')(bn1)   #32x32 \n",
        "# activation_x2 = Activation('relu')(x2)\n",
        "# bn2 = BatchNormalization()(activation_x2)\n",
        "\n",
        "# x3 = Convolution2D(64, (3, 3),padding='same')(bn2)   #32x32 \n",
        "# activation_x3 = Activation('relu')(x3)\n",
        "# bn3 = BatchNormalization()(activation_x3)\n",
        "\n",
        "\n",
        "##block 1\n",
        "\n",
        "blk1 = ResNetBlock(bn1,32)  ##32x32\n",
        "z1 = add([blk1,bn1])\n",
        "\n",
        "blk1_c = ResNetBlock(z1,32)\n",
        "z1_c = add([blk1_c,z1])\n",
        "\n",
        "drp1 = SpatialDropout2D(0.15)(z1_c)\n",
        "\n",
        "##block 2\n",
        "\n",
        "blk2 = ResNetBlock(drp1,64,stride=2)\n",
        "one_blk = Convolution2D(64, (1, 1), padding='same',strides=2)(drp1)\n",
        "z2 = add([blk2,one_blk])\n",
        "\n",
        "blk2_c = ResNetBlock(z2,64)\n",
        "z2_c = add([blk2_c,z2])\n",
        "\n",
        "drp2 = SpatialDropout2D(0.15)(z2_c)\n",
        "\n",
        "##block3\n",
        "\n",
        "blk3 = ResNetBlock(drp2,128)\n",
        "one_blk_1 = Convolution2D(128, (1, 1), padding='same')(drp2)\n",
        "z3 = add([blk3,one_blk_1])\n",
        "\n",
        "blk3_c = ResNetBlock(z3,128)\n",
        "z3_c = add([blk3_c,z3])\n",
        "\n",
        "drp3 = SpatialDropout2D(0.15)(z3_c)\n",
        "##block4\n",
        "\n",
        "blk4 = ResNetBlock(drp3,256,stride=2)\n",
        "one_blk_2 = Convolution2D(256, (1, 1), padding='same',strides=2)(drp3)\n",
        "z4 = add([blk4,one_blk_2])\n",
        "\n",
        "blk4_c = ResNetBlock(z4,256)\n",
        "z4_c = add([blk4_c,z4])\n",
        "\n",
        "\n",
        "avg_pool_layer = GlobalAveragePooling2D()(z4_c)\n",
        "\n",
        "#flatten_layer = Flatten()(avg_pool_layer)\n",
        "\n",
        "fc_layer = Dense(10, activation='softmax')(avg_pool_layer)\n",
        "\n",
        "\n",
        "model = Model(inputs=inputs, outputs= fc_layer)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0804 19:58:59.018450 139749233948544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0804 19:58:59.054064 139749233948544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0804 19:58:59.062936 139749233948544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0804 19:58:59.101377 139749233948544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0804 19:58:59.102168 139749233948544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0804 19:59:01.805094 139749233948544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0804 19:59:02.302281 139749233948544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sV-nVdlMDwva",
        "outputId": "df62b963-b954-4921-8158-a39216c8c486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9248        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 32)   0           conv2d_3[0][0]                   \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   9248        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 32)   0           conv2d_5[0][0]                   \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_1 (SpatialDro (None, 32, 32, 32)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 64)   18496       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   2112        spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 64)   0           conv2d_7[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 64)   36928       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 64)   0           conv2d_10[0][0]                  \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_2 (SpatialDro (None, 16, 16, 64)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         spatial_dropout2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 128)  73856       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 128)  8320        spatial_dropout2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 128)  147584      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 128)  0           conv2d_15[0][0]                  \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_3 (SpatialDro (None, 16, 16, 128)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         spatial_dropout2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 256)    295168      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 256)    1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 256)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 256)    590080      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 256)    33024       spatial_dropout2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 256)    0           conv2d_17[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 256)    1024        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 256)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 256)    590080      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 256)    1024        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 256)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 256)    590080      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 256)    0           conv2d_20[0][0]                  \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 256)          0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           2570        global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 2,802,122\n",
            "Trainable params: 2,798,666\n",
            "Non-trainable params: 3,456\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZl_uafGb3r9",
        "colab": {}
      },
      "source": [
        "#from one_cycle_lr import LRFinder\n",
        "from one_cycle_lr import LRFinder\n",
        "num_samples= train_features.shape[0]\n",
        "batch_size = 512\n",
        "num_epoch=50\n",
        "max_lr= 0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDMPrA1Gj01s"
      },
      "source": [
        "#Best LR would be 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PjzOgXaWj_uE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ff12ddcc-4e0c-412f-bc61-0f7c54fd08ea"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "opt = optimizers.SGD()\n",
        "model.compile(optimizer=opt , loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0804 19:59:03.537996 139749233948544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XaDmx-zQlExS",
        "colab": {}
      },
      "source": [
        "from one_cycle_lr import OneCycleLR\n",
        "\n",
        "lr_manager = OneCycleLR(num_samples, num_epoch, batch_size, max_lr,\n",
        "                        end_percentage=0.1, scale_percentage=None,\n",
        "                        maximum_momentum=0.95, minimum_momentum=0.85)\n",
        "                        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sDeQk2bZqTGp",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "upsNiPO4JWjb",
        "outputId": "0e2315a5-5514-42f8-c4be-76626a43e52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filepath = \"Resnet-13.hdf5\"\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 512),\n",
        "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 300, \n",
        "                                 validation_data = (test_features, test_labels), verbose=1,callbacks=[checkpoint,lr_manager])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., verbose=1, callbacks=[<keras.ca..., steps_per_epoch=97, epochs=300)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "W0804 19:59:03.705912 139749233948544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "97/97 [==============================] - 38s 396ms/step - loss: 2.7957 - acc: 0.1942 - val_loss: 14.3505 - val_acc: 0.1008\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.10080, saving model to Resnet-13.hdf5\n",
            " - lr: 0.01396 - momentum: 0.95 \n",
            "Epoch 2/300\n",
            "97/97 [==============================] - 33s 342ms/step - loss: 1.7817 - acc: 0.3330 - val_loss: 3.0750 - val_acc: 0.1985\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.10080 to 0.19850, saving model to Resnet-13.hdf5\n",
            " - lr: 0.01796 - momentum: 0.94 \n",
            "Epoch 3/300\n",
            "97/97 [==============================] - 33s 342ms/step - loss: 1.6494 - acc: 0.3891 - val_loss: 1.9723 - val_acc: 0.3090\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.19850 to 0.30900, saving model to Resnet-13.hdf5\n",
            " - lr: 0.02196 - momentum: 0.94 \n",
            "Epoch 4/300\n",
            "97/97 [==============================] - 32s 334ms/step - loss: 1.5592 - acc: 0.4218 - val_loss: 2.2239 - val_acc: 0.2945\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.30900\n",
            " - lr: 0.02596 - momentum: 0.93 \n",
            "Epoch 5/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 1.4421 - acc: 0.4686 - val_loss: 1.7747 - val_acc: 0.3517\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.30900 to 0.35170, saving model to Resnet-13.hdf5\n",
            " - lr: 0.02996 - momentum: 0.93 \n",
            "Epoch 6/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 1.3375 - acc: 0.5138 - val_loss: 2.1453 - val_acc: 0.3650\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.35170 to 0.36500, saving model to Resnet-13.hdf5\n",
            " - lr: 0.03396 - momentum: 0.92 \n",
            "Epoch 7/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 1.2494 - acc: 0.5493 - val_loss: 2.0463 - val_acc: 0.3778\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.36500 to 0.37780, saving model to Resnet-13.hdf5\n",
            " - lr: 0.03797 - momentum: 0.92 \n",
            "Epoch 8/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 1.1635 - acc: 0.5811 - val_loss: 2.0619 - val_acc: 0.4558\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.37780 to 0.45580, saving model to Resnet-13.hdf5\n",
            " - lr: 0.04197 - momentum: 0.91 \n",
            "Epoch 9/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 1.0965 - acc: 0.6074 - val_loss: 1.6335 - val_acc: 0.4585\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.45580 to 0.45850, saving model to Resnet-13.hdf5\n",
            " - lr: 0.04597 - momentum: 0.91 \n",
            "Epoch 10/300\n",
            "97/97 [==============================] - 33s 338ms/step - loss: 1.0339 - acc: 0.6317 - val_loss: 1.4244 - val_acc: 0.5663\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.45850 to 0.56630, saving model to Resnet-13.hdf5\n",
            " - lr: 0.04997 - momentum: 0.91 \n",
            "Epoch 11/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 1.0028 - acc: 0.6444 - val_loss: 2.0626 - val_acc: 0.4142\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.56630\n",
            " - lr: 0.05397 - momentum: 0.90 \n",
            "Epoch 12/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.9302 - acc: 0.6700 - val_loss: 1.2341 - val_acc: 0.5964\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.56630 to 0.59640, saving model to Resnet-13.hdf5\n",
            " - lr: 0.05797 - momentum: 0.90 \n",
            "Epoch 13/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 0.8844 - acc: 0.6876 - val_loss: 1.5385 - val_acc: 0.5637\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.59640\n",
            " - lr: 0.06197 - momentum: 0.89 \n",
            "Epoch 14/300\n",
            "97/97 [==============================] - 33s 338ms/step - loss: 0.8512 - acc: 0.7009 - val_loss: 1.2012 - val_acc: 0.6589\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.59640 to 0.65890, saving model to Resnet-13.hdf5\n",
            " - lr: 0.06597 - momentum: 0.89 \n",
            "Epoch 15/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 0.8195 - acc: 0.7110 - val_loss: 1.2620 - val_acc: 0.6324\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.65890\n",
            " - lr: 0.06997 - momentum: 0.88 \n",
            "Epoch 16/300\n",
            "97/97 [==============================] - 33s 338ms/step - loss: 0.7755 - acc: 0.7280 - val_loss: 1.4100 - val_acc: 0.6511\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.65890\n",
            " - lr: 0.07397 - momentum: 0.88 \n",
            "Epoch 17/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.7405 - acc: 0.7400 - val_loss: 0.7284 - val_acc: 0.7506\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.65890 to 0.75060, saving model to Resnet-13.hdf5\n",
            " - lr: 0.07797 - momentum: 0.87 \n",
            "Epoch 18/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 0.7088 - acc: 0.7520 - val_loss: 1.1296 - val_acc: 0.6666\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.75060\n",
            " - lr: 0.08198 - momentum: 0.87 \n",
            "Epoch 19/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 0.7005 - acc: 0.7565 - val_loss: 1.3368 - val_acc: 0.6791\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.75060\n",
            " - lr: 0.08598 - momentum: 0.87 \n",
            "Epoch 20/300\n",
            "97/97 [==============================] - 33s 338ms/step - loss: 0.6659 - acc: 0.7670 - val_loss: 0.8604 - val_acc: 0.7372\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.75060\n",
            " - lr: 0.08998 - momentum: 0.86 \n",
            "Epoch 21/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.6449 - acc: 0.7753 - val_loss: 0.8957 - val_acc: 0.7313\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.75060\n",
            " - lr: 0.09398 - momentum: 0.86 \n",
            "Epoch 22/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.6298 - acc: 0.7817 - val_loss: 0.5725 - val_acc: 0.8059\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.75060 to 0.80590, saving model to Resnet-13.hdf5\n",
            " - lr: 0.09798 - momentum: 0.85 \n",
            "Epoch 23/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.6157 - acc: 0.7860 - val_loss: 0.7685 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80590\n",
            " - lr: 0.09802 - momentum: 0.85 \n",
            "Epoch 24/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.5904 - acc: 0.7939 - val_loss: 0.8633 - val_acc: 0.7466\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80590\n",
            " - lr: 0.09402 - momentum: 0.86 \n",
            "Epoch 25/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 0.5606 - acc: 0.8052 - val_loss: 0.6982 - val_acc: 0.7810\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80590\n",
            " - lr: 0.09002 - momentum: 0.86 \n",
            "Epoch 26/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.5450 - acc: 0.8102 - val_loss: 0.8138 - val_acc: 0.7652\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80590\n",
            " - lr: 0.08602 - momentum: 0.87 \n",
            "Epoch 27/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.5424 - acc: 0.8090 - val_loss: 0.6756 - val_acc: 0.7936\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80590\n",
            " - lr: 0.08202 - momentum: 0.87 \n",
            "Epoch 28/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.5173 - acc: 0.8188 - val_loss: 0.5266 - val_acc: 0.8271\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.80590 to 0.82710, saving model to Resnet-13.hdf5\n",
            " - lr: 0.07802 - momentum: 0.87 \n",
            "Epoch 29/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 0.5062 - acc: 0.8235 - val_loss: 0.5207 - val_acc: 0.8403\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.82710 to 0.84030, saving model to Resnet-13.hdf5\n",
            " - lr: 0.07401 - momentum: 0.88 \n",
            "Epoch 30/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.4983 - acc: 0.8276 - val_loss: 0.5560 - val_acc: 0.8243\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.84030\n",
            " - lr: 0.07001 - momentum: 0.88 \n",
            "Epoch 31/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.4702 - acc: 0.8364 - val_loss: 0.4799 - val_acc: 0.8406\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.84030 to 0.84060, saving model to Resnet-13.hdf5\n",
            " - lr: 0.06601 - momentum: 0.89 \n",
            "Epoch 32/300\n",
            "97/97 [==============================] - 33s 335ms/step - loss: 0.4588 - acc: 0.8397 - val_loss: 0.5939 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.84060\n",
            " - lr: 0.06201 - momentum: 0.89 \n",
            "Epoch 33/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.4559 - acc: 0.8418 - val_loss: 0.5236 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.84060\n",
            " - lr: 0.05801 - momentum: 0.90 \n",
            "Epoch 34/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.4355 - acc: 0.8485 - val_loss: 0.5132 - val_acc: 0.8446\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.84060 to 0.84460, saving model to Resnet-13.hdf5\n",
            " - lr: 0.05401 - momentum: 0.90 \n",
            "Epoch 35/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.4344 - acc: 0.8460 - val_loss: 0.4385 - val_acc: 0.8572\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.84460 to 0.85720, saving model to Resnet-13.hdf5\n",
            " - lr: 0.05001 - momentum: 0.91 \n",
            "Epoch 36/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.4122 - acc: 0.8558 - val_loss: 0.4230 - val_acc: 0.8679\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.85720 to 0.86790, saving model to Resnet-13.hdf5\n",
            " - lr: 0.04601 - momentum: 0.91 \n",
            "Epoch 37/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.4131 - acc: 0.8556 - val_loss: 0.6434 - val_acc: 0.8050\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.86790\n",
            " - lr: 0.04201 - momentum: 0.91 \n",
            "Epoch 38/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3920 - acc: 0.8615 - val_loss: 0.4664 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.86790\n",
            " - lr: 0.03801 - momentum: 0.92 \n",
            "Epoch 39/300\n",
            "97/97 [==============================] - 33s 335ms/step - loss: 0.3784 - acc: 0.8681 - val_loss: 0.4029 - val_acc: 0.8720\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.86790 to 0.87200, saving model to Resnet-13.hdf5\n",
            " - lr: 0.03401 - momentum: 0.92 \n",
            "Epoch 40/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3722 - acc: 0.8698 - val_loss: 0.5543 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.87200\n",
            " - lr: 0.03000 - momentum: 0.93 \n",
            "Epoch 41/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3623 - acc: 0.8734 - val_loss: 0.4680 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.87200\n",
            " - lr: 0.02600 - momentum: 0.93 \n",
            "Epoch 42/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3465 - acc: 0.8785 - val_loss: 0.4742 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.87200\n",
            " - lr: 0.02200 - momentum: 0.94 \n",
            "Epoch 43/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3383 - acc: 0.8818 - val_loss: 0.4088 - val_acc: 0.8687\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.87200\n",
            " - lr: 0.01800 - momentum: 0.94 \n",
            "Epoch 44/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3293 - acc: 0.8841 - val_loss: 0.3924 - val_acc: 0.8811\n",
            "\n",
            "Epoch 00044: val_acc improved from 0.87200 to 0.88110, saving model to Resnet-13.hdf5\n",
            " - lr: 0.01400 - momentum: 0.95 \n",
            "Epoch 45/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3120 - acc: 0.8907 - val_loss: 0.3344 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00045: val_acc improved from 0.88110 to 0.89690, saving model to Resnet-13.hdf5\n",
            " - lr: 0.01000 - momentum: 0.95 \n",
            "Epoch 46/300\n",
            "97/97 [==============================] - 33s 337ms/step - loss: 0.2950 - acc: 0.8967 - val_loss: 0.3481 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.89690\n",
            " - lr: 0.00802 - momentum: 0.95 \n",
            "Epoch 47/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.2904 - acc: 0.8985 - val_loss: 0.3231 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.89690 to 0.90030, saving model to Resnet-13.hdf5\n",
            " - lr: 0.00605 - momentum: 0.95 \n",
            "Epoch 48/300\n",
            "97/97 [==============================] - 33s 335ms/step - loss: 0.2811 - acc: 0.9005 - val_loss: 0.3039 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00048: val_acc improved from 0.90030 to 0.90490, saving model to Resnet-13.hdf5\n",
            " - lr: 0.00407 - momentum: 0.95 \n",
            "Epoch 49/300\n",
            "97/97 [==============================] - 33s 335ms/step - loss: 0.2732 - acc: 0.9040 - val_loss: 0.2929 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.90490 to 0.90810, saving model to Resnet-13.hdf5\n",
            " - lr: 0.00210 - momentum: 0.95 \n",
            "Epoch 50/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.2620 - acc: 0.9071 - val_loss: 0.2894 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00050: val_acc improved from 0.90810 to 0.90940, saving model to Resnet-13.hdf5\n",
            " - lr: 0.00012 - momentum: 0.95 \n",
            "Epoch 51/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.2796 - acc: 0.9010 - val_loss: 0.3642 - val_acc: 0.8931\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.90940\n",
            " - lr: 0.01396 - momentum: 0.95 \n",
            "Epoch 52/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.2965 - acc: 0.8957 - val_loss: 0.4122 - val_acc: 0.8797\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.90940\n",
            " - lr: 0.01796 - momentum: 0.94 \n",
            "Epoch 53/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3088 - acc: 0.8899 - val_loss: 0.4138 - val_acc: 0.8747\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.90940\n",
            " - lr: 0.02196 - momentum: 0.94 \n",
            "Epoch 54/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3178 - acc: 0.8881 - val_loss: 0.4031 - val_acc: 0.8816\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.90940\n",
            " - lr: 0.02596 - momentum: 0.93 \n",
            "Epoch 55/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3243 - acc: 0.8870 - val_loss: 0.4772 - val_acc: 0.8691\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.90940\n",
            " - lr: 0.02996 - momentum: 0.93 \n",
            "Epoch 56/300\n",
            "97/97 [==============================] - 33s 335ms/step - loss: 0.3282 - acc: 0.8859 - val_loss: 0.3368 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.90940\n",
            " - lr: 0.03396 - momentum: 0.92 \n",
            "Epoch 57/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3176 - acc: 0.8882 - val_loss: 0.4451 - val_acc: 0.8704\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.90940\n",
            " - lr: 0.03797 - momentum: 0.92 \n",
            "Epoch 58/300\n",
            "97/97 [==============================] - 33s 335ms/step - loss: 0.3273 - acc: 0.8833 - val_loss: 0.4734 - val_acc: 0.8572\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.90940\n",
            " - lr: 0.04197 - momentum: 0.91 \n",
            "Epoch 59/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3278 - acc: 0.8858 - val_loss: 0.4628 - val_acc: 0.8702\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.90940\n",
            " - lr: 0.04597 - momentum: 0.91 \n",
            "Epoch 60/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3235 - acc: 0.8864 - val_loss: 0.3553 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.90940\n",
            " - lr: 0.04997 - momentum: 0.91 \n",
            "Epoch 61/300\n",
            "97/97 [==============================] - 33s 336ms/step - loss: 0.3293 - acc: 0.8842 - val_loss: 0.4344 - val_acc: 0.8696\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.90940\n",
            " - lr: 0.05397 - momentum: 0.90 \n",
            "Epoch 62/300\n",
            "97/97 [==============================] - 33s 335ms/step - loss: 0.3293 - acc: 0.8836 - val_loss: 0.4660 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.90940\n",
            " - lr: 0.05797 - momentum: 0.90 \n",
            "Epoch 63/300\n",
            "26/97 [=======>......................] - ETA: 22s - loss: 0.3223 - acc: 0.8857"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4d84fe79bb36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 512),\n\u001b[1;32m      9\u001b[0m                                  \u001b[0msamples_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                  validation_data = (test_features, test_labels), verbose=1,callbacks=[checkpoint,lr_manager])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ADKRdQnkKQ_z",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}